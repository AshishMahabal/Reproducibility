import matplotlib
matplotlib.use('Agg')

import os
import copy
import generate
import numpy
import theano.sandbox.cuda
theano.sandbox.cuda.use("gpu" + str(0))
import lasagne
from nolearn.lasagne import NeuralNet, objective, TrainSplit
from lasagne.nonlinearities import softmax, rectify
from lasagne.layers import InputLayer
from lasagne.layers import Conv2DLayer
from lasagne.layers import MaxPool2DLayer
from lasagne.layers import DropoutLayer
from lasagne.layers import DenseLayer
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from util import plot_confusion, plot_misclassifications

# parameters
epochs = 500
learning_rate = 0.0002
verbose = 1
seed = 0
classes = [1,2,4,5,6,8,13]
#what are classes
	
test_size = 0.2

# get data and encode labels
X_2d, X_features, y, indices = generate.get_data("all", classes=classes, shuffle=True, seed=seed)
labelencoder = preprocessing.LabelEncoder()
labelencoder.fit(y)
y = labelencoder.transform(y).astype(numpy.int32)
print("Total number of instances: " + str(len(y)))

# split data (train/test)
X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X_2d, y, indices, test_size=test_size, random_state=seed)
X_test_plot = copy.deepcopy(X_test)
#why reshaping ?
X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1], X_train.shape[2]))
X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1], X_test.shape[2]))
print("Number of training instances: %i" % len(y_train))
print("Number of test instances: %i" % len(y_test))

layers = [
    (InputLayer, {'shape': (None, X_train.shape[1], X_train.shape[2], X_train.shape[3])}),

    (Conv2DLayer, {'num_filters': 64, 'filter_size': (3, 3), 'pad': 0, 'nonlinearity':rectify}),
    (MaxPool2DLayer, {'pool_size': (2, 2)}),
    (DropoutLayer, {'p':0.1}),

    (Conv2DLayer, {'num_filters': 128, 'filter_size': (5, 5), 'pad': 0, 'nonlinearity':rectify}),
    #(MaxPool2DLayer, {'pool_size': (2, 2)}),
    #(DropoutLayer, {'p':0.3}),         

    (Conv2DLayer, {'num_filters': 256, 'filter_size': (5, 5), 'pad': 0, 'nonlinearity':rectify}),
    #(MaxPool2DLayer, {'pool_size': (2, 2)}),
    #(DropoutLayer, {'p':0.5}),       

    (DenseLayer, {'num_units': 512}),
    (DropoutLayer, {'p':0.5}),
    (DenseLayer, {'num_units': 512}),

    (DenseLayer, {'num_units': len(list(set(y))), 'nonlinearity': softmax}),
]

net = NeuralNet(
    layers=layers,
    max_epochs=epochs,
    update=lasagne.updates.adam,
    update_learning_rate=learning_rate,
    objective_l2=0.0025,
    train_split=TrainSplit(eval_size=0.05),
    verbose=verbose,
)

net.fit(X_train, y_train)
preds = net.predict(X_test)
preds_proba = net.predict_proba(X_test)
acc = accuracy_score(y_test, preds)
print("Accuracy: %f" % acc)

y_test = labelencoder.inverse_transform(y_test)
preds = labelencoder.inverse_transform(preds)

# plot misclassifications
plot_misclassifications(y_test, preds, X_test_plot, indices_test, "cnn/misclassifications")

# save output
numpy.savetxt("cnn/y_test_cnn.csv", y_test, delimiter=",", fmt='%.4f')
numpy.savetxt("cnn/preds_cnn.csv", preds, delimiter=",", fmt='%.4f')
numpy.savetxt("cnn/preds_proba_cnn.csv", preds_proba, delimiter=",", fmt='%.4f')
plot_confusion(y_test, preds, "cnn/confusion_cnn.png")
